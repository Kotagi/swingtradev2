# Project README

*Auto-generated by `generate_readme.py`*

## Quickstart

```bash
python src/download_data.py --tickers data/tickers/sp500_tickers.csv
python src/clean_data.py
run_features_labels.bat
python src/train_model.py
```

```
bats/
  ├─ run_feature_pipeline.bat
config/
  ├─ features.yaml
  ├─ train_features.yaml
data/
  ├─ clean/
  ├─ features_labeled/
  ├─ inspect_parquet/
  ├─ raw/
  ├─ tickers/
    ├─ Archive/
features/
  ├─ __init__.py
  ├─ registry.py
  ├─ technical.py
models/
notebooks/
reports/
  ├─ trade_logs/
scripts/
src/
  ├─ __init__.py
  ├─ backtest.py
  ├─ clean_data.py
  ├─ clean_features_labeled.py
  ├─ download_data.py
  ├─ feature_pipeline.py
  ├─ inspect_parquet.py
  ├─ train_model.py
tests/
  ├─ archive/
    ├─ test_clean_data.py
    ├─ test_features.py
    ├─ test_features_base.py
    ├─ test_labeling.py
utils/
  ├─ __init__.py
  ├─ labeling.py
  ├─ logger.py
clean_data.bat
clean_features.bat
download_data.bat
download_data_full.bat
profile_pipeline.bat
read_clean_parquet.bat
read_feature_parquet.bat
readme_generator.py
redownload_and_clean.bat
run_features_labels.bat
```

## Dependencies

**requirements.txt:**
- `pandas>=1.3`
- `numpy>=1.21`
- `requests>=2.25`
- `pytest>=7.0`
- `python-dotenv>=0.19`
- `tabulate>=0.8.9`
- `matplotlib>=3.4`
- `pandas-ta>=0.3.14`
- `pyarrow>=20.0.0`
- `shap>=0.41.0`


## Config Files

- **config\features.yaml**: pipeline feature toggles (keys: features)
- **config\train_features.yaml**: training feature toggles (keys: features)


## CLI Reference

### `src\download_data.py`

| Flag | Help | Default |
| ---- | ---- | ------- |
| `-f, --tickers-file` | Path to a file with one ticker symbol per line | 'data/tickers/sp500_tickers.csv' |
| `-s, --start-date` | Start date for historical data (YYYY-MM-DD) | '2008-01-01' |
| `-e, --end-date` | End date (exclusive) for historical data (YYYY-MM-DD); defaults to today | None |
| `-r, --raw-folder` | Directory to save downloaded raw CSV files | 'data/raw' |
| `-o, --sectors-file` | Output CSV for ticker–sector mapping | 'data/tickers/sectors.csv' |
| `--full, --force-full` | Ignore existing files and re-download entire history for every ticker | - |

### `src\feature_pipeline.py`

| Flag | Help | Default |
| ---- | ---- | ------- |
| `--input-dir` | Cleaned Parqs | - |
| `--output-dir` | Features Parqs | - |
| `--config` | features.yaml | - |
| `--horizon` | Label days | 5 |
| `--threshold` | Return thresh | 0.0 |
| `--full, --force-full` | Recompute all tickers, ignoring cache | - |

### `src\inspect_parquet.py`

| Flag | Help | Default |
| ---- | ---- | ------- |
| `parquet_file` | Path to the Parquet file to inspect (e.g. data/clean/AAPL.parquet). | - |
| `--export-dir, -e` | Directory where the full CSV will be saved (default: data/inspect_parquet) | - |

### `src\train_model.py`

| Flag | Help | Default |
| ---- | ---- | ------- |
| `--diagnostics` | Compute and print feature importances and SHAP diagnostics | - |


## Modules

### `src\backtest.py`
backtest.py
**Functions:**
- `load_universe(tickers_csv)`  
  Load the list of tickers from a CSV file.
- `backtest_signals(df, signal_col, horizon, position_size)`  
  Backtest a boolean entry signal over a fixed holding period.
- `aggregate_results(trades)`  
  Compute summary performance metrics from a series of trades.
- `main()`  
  Main entry point: executes backtests for oracle and RSI strategies,

### `src\clean_data.py`
clean_data.py
**Functions:**
- `clean_file(path)`  
  Clean a single raw CSV file and return any integrity issues.
- `main()`  
  Entry point: cleans all CSVs under RAW_DIR and logs a summary.

### `src\clean_features_labeled.py`
clean_features_labeled.py
**Functions:**
- `clean_file(path)`  
  Clean a single labeled feature Parquet file in-place.
- `main()`  
  Locate all Parquet files under DATA_DIR and clean each using clean_file().

### `src\download_data.py`
download_data.py
**Functions:**
- `download_data(tickers, start_date, end_date, raw_folder, full_refresh)`  
  Download OHLCV data and fetch sector info for each ticker.
- `write_sectors_csv(sectors, sectors_file)`  
  Write the ticker-to-sector mapping to a CSV file.
- `main()`  
  Parse command-line arguments, download data, and write sector mapping.

### `src\feature_pipeline.py`
feature_pipeline.py
**Functions:**
- `apply_features(df, enabled_features, logger)`  
  Apply each enabled feature function to the DataFrame.
- `process_file(file_path, output_path, enabled, label_horizon, label_threshold, log_file, full_refresh)`  
  Worker: process one ticker end-to-end with optional caching.
- `main(input_dir, output_dir, config_path, label_horizon, label_threshold, full_refresh)`  
  Entry point: parallelize processing with optional full-refresh.

### `src\inspect_parquet.py`
inspect_parquet.py
**Functions:**
- `main()`

### `src\train_model.py`
train_model.py
**Functions:**
- `load_data()`  
  Load all ticker feature Parquet files into one concatenated DataFrame.
- `prepare(df)`  
  Clean and split the raw DataFrame into X (features) and y (target).
- `main()`  
  Main routine to train and evaluate the model.

### `utils\labeling.py`
labeling.py
**Functions:**
- `label_future_return(df, close_col, horizon, threshold, label_name)`  
  Add a binary label column to indicate if the forward return exceeds a threshold.
- `label_future_return_regression(df, close_col, horizon, label_name)`  
  Add a continuous target column representing the future return.

### `utils\logger.py`
logger.py
**Functions:**
- `setup_logger(name, log_file, level)`  
  Configure and return a Logger instance.

### `features\registry.py`
registry.py
**Functions:**
- `load_enabled_features(config_path)`  
  Load the feature-toggle YAML and return only the enabled features.

### `features\technical.py`
technical.py
**Functions:**
- `_get_close_series(df)`  
  Return the 'close' price series, handling both lowercase and uppercase.
- `feature_log_return_1d(df)`  
  Compute 1-day log return: ln(close_t / close_{t-1}).
- `feature_log_return_5d(df)`  
  Compute 5-day log return: ln(close_t / close_{t-5}).
- `feature_5d_return(df)`  
  Compute 5-day forward return: (close_{t+5} / close_t) - 1.
- `feature_10d_return(df)`  
  Compute 10-day forward return: (close_{t+10} / close_t) - 1.
- `feature_close_vs_ma10(df)`  
  Compute the ratio of today's close to its 10-day simple moving average.
- `feature_close_vs_ma20(df)`  
  Compute the ratio of today's close to its 20-day simple moving average.
- `feature_close_zscore_20(df)`  
  Compute the 20-day rolling z-score of today’s close:
- `feature_price_percentile_20d(df)`  
  Compute the 20-day rolling percentile rank of today’s close.
- `feature_gap_up_pct(df)`  
  Compute the percent gap-up at open relative to prior close:
- `feature_daily_range_pct(df)`  
  Compute the percent size of the intraday high-low range relative to open:
- `feature_candle_body_pct(df)`  
  Compute the percent size of the candle body relative to the high-low range:
- `feature_close_position_in_range(df)`  
  Compute the relative position of the close within the intraday range:
- `feature_high_vs_close(df)`  
  Compute the percent difference between the intraday high and the close:
- `feature_rolling_max_5d_breakout(df)`  
  Compute the percent that today’s close exceeds the max close of the prior 5 days:
- `feature_rolling_min_5d_breakdown(df)`  
  Compute the percent that today’s close falls below the min close of the prior 5 days:
- `feature_atr(df, period)`  
  Compute Average True Range (ATR) over a given period via pandas-ta.
- `feature_atr_pct_of_price(df)`  
  Compute the Average True Range as a percent of today's close:
- `feature_bb_width(df, period, std_dev)`  
  Compute Bollinger Band width: (upper_band - lower_band) / middle_band.
- `feature_ema_cross(df, span_short, span_long)`  
  Compute EMA difference: EMA(short) - EMA(long).
- `feature_obv(df)`  
  Compute On-Balance Volume (OBV) via pandas-ta.
- `feature_obv_pct(df, length)`  
  Compute daily percent change of OBV via Rate-of-Change.
- `feature_obv_zscore(df, length)`  
  Compute z-score of OBV relative to its moving average.
- `feature_volume_avg_ratio_5d(df)`  
  Compute the ratio of today's volume to the prior 5-day average volume.
- `feature_rsi(df, period)`  
  Compute Relative Strength Index (RSI) via pandas-ta.
- `feature_sma_5(df)`  
  Compute 5-day Simple Moving Average via pandas-ta.
- `feature_ema_5(df)`  
  Compute 5-day Exponential Moving Average via pandas-ta.
- `feature_sma_10(df)`  
  Compute 10-day Simple Moving Average via pandas-ta.
- `feature_ema_10(df)`  
  Compute 10-day Exponential Moving Average via pandas-ta.
- `feature_sma_50(df)`  
  Compute 50-day Simple Moving Average via pandas-ta.
- `feature_ema_50(df)`  
  Compute 50-day Exponential Moving Average via pandas-ta.
- `feature_adx_14(df, period)`  
  Compute 14-day Average Directional Index (ADX) via pandas-ta.

---
## Enabled Features

- **10d_return**: ✅
- **5d_return**: ✅
- **adx_14**: ✅
- **atr**: ✅
- **atr_pct_of_price**: ✅
- **bb_width**: ✅
- **candle_body_pct**: ✅
- **close_position_in_range**: ✅
- **close_vs_ma10**: ✅
- **close_vs_ma20**: ✅
- **close_zscore_20**: ✅
- **daily_range_pct**: ✅
- **ema_10**: ✅
- **ema_5**: ✅
- **ema_50**: ✅
- **ema_cross**: ✅
- **gap_up_pct**: ✅
- **high_vs_close**: ✅
- **log_return_1d**: ✅
- **log_return_5d**: ✅
- **obv**: ✅
- **obv_pct**: ✅
- **obv_z20**: ✅
- **price_percentile_20d**: ✅
- **rolling_max_5d_breakout**: ✅
- **rolling_min_5d_breakdown**: ✅
- **rsi**: ✅
- **sma_10**: ✅
- **sma_5**: ✅
- **sma_50**: ✅
- **volume_avg_ratio_5d**: ✅

